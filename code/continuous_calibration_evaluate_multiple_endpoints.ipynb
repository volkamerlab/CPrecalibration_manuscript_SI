{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate strategies over multiple endpoints using boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates, how the predictions could be evaluated using boxplots.\n",
    "\n",
    "For each endpoints, ACP's are trained both 'with and without normaliser model' and 'with and without updating the calibration set'. In this example, the calibration set is even updated twice. \n",
    "\n",
    "For comparison over all endpoints, the rmsd to the diagonal line in the calibration plot (significance level) is calculated. Here, the rmsd over all compounds is calculated, alternatively, we could also calculate it class-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.nc import InverseProbabilityErrFunc, NcFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define path to import script(s) from\n",
    "# scripts_path = \"../scripts/\"\n",
    "# sys.path.append(scripts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from continuous_calibration import (\n",
    "StratifiedRatioSampler, BalancedStratifiedRatioSampler, CrossValidationSampler, InductiveConformalPredictor, \n",
    "    ContinuousCalibrationAggregatedConformalPredictor, CrossValidator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/chembl_chembio_descriptors.tar.bz2\"\n",
    "time_split_threshold_path = \"../data/data_size_chembio_chembl.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHEMBL279', 'CHEMBL220', 'CHEMBL4078', 'CHEMBL5763', 'CHEMBL203', 'CHEMBL206', 'CHEMBL222', 'CHEMBL228', 'CHEMBL230', 'CHEMBL340', 'CHEMBL240', 'CHEMBL2039']\n"
     ]
    }
   ],
   "source": [
    "endpoint_dict = {\n",
    "    \"CHEMBL279\": [\"VEGFR 2\", \"Vascular endothelial growth factor receptor 2\"],\n",
    "    \"CHEMBL220\": [\"Acetylcholinesterase\"],\n",
    "    \"CHEMBL4078\": [\"Acetylcholinesterase\"],\n",
    "    \"CHEMBL5763\": [\"Cholinesterase\"],\n",
    "    \"CHEMBL203\": [\"EGFR erbB1\", \"Epidermal growth factor receptor erbB1\"],\n",
    "    \"CHEMBL206\": [\"Estrogen receptor alpha\"],\n",
    "    \"CHEMBL222\": [\"Norepinephrine transporter\"],\n",
    "    \"CHEMBL228\": [\"Serotonin transporter\"],\n",
    "    \"CHEMBL230\": [\"Cyclooxygenase-2\"],\n",
    "    \"CHEMBL340\": [\"Cytochrome P450 3A4\"],\n",
    "    \"CHEMBL240\": [\"HERG\"],\n",
    "    \"CHEMBL2039\": [\"Monoamine oxidase B\"],\n",
    "}\n",
    "\n",
    "endpoints = list(endpoint_dict.keys())\n",
    "print(endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrees = 50\n",
    "n_folds_acp = 3 # 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_per_endpoint(data_dict, endpoint):\n",
    "    data = data_dict[endpoint]\n",
    "    data.dropna(subset=[\"year\"], inplace=True)\n",
    "    y = data[f\"{endpoint}_bioactivity\"].values\n",
    "    columns = [col for col in data.columns if col.startswith('p') or col.startswith('byte')]\n",
    "    X = data[columns].values\n",
    "    years = data[\"year\"].values\n",
    "    return X, y, years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_per_endpoint(X, y, years, splits_df):\n",
    "    thresholds = splits_df[\"train_thresh\"][endpoint], splits_df[\"update1_thresh\"][endpoint], splits_df[\"update2_thresh\"][endpoint]\n",
    "    \n",
    "    mask_train = years <= thresholds[0]\n",
    "    mask_update1 = (years > thresholds[0]) & (years <= thresholds[1])\n",
    "    mask_update2 = (years > thresholds[1]) & (years <= thresholds[2])\n",
    "    mask_holdout = years > thresholds[2]\n",
    "\n",
    "    X_train, y_train = X[mask_train], y[mask_train]\n",
    "    X_update1, y_update1 = X[mask_update1], y[mask_update1]\n",
    "    X_update2, y_update2 = X[mask_update2], y[mask_update2]\n",
    "    X_holdout, y_holdout = X[mask_holdout], y[mask_holdout]\n",
    "    \n",
    "    return X_train, X_update1, X_update2, X_holdout, y_train, y_update1, y_update2, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rf_acp():\n",
    "    clf = RandomForestClassifier(n_estimators=ntrees)\n",
    "    error_function = InverseProbabilityErrFunc()\n",
    "    nc = NcFactory.create_nc(clf, err_func=error_function, normalizer_model=None)\n",
    "    icp = InductiveConformalPredictor(nc_function=nc, condition=(lambda instance: instance[1]), \n",
    "                                      smoothing=False)\n",
    "    ratio_sampler = StratifiedRatioSampler(n_folds=n_folds_acp)\n",
    "    acp = ContinuousCalibrationAggregatedConformalPredictor(\n",
    "        predictor=icp, sampler=ratio_sampler, aggregation_func=np.median)\n",
    "    return acp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deviation_square(error, sl):\n",
    "    return (error-sl)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmsd_from_df(eval_df, cl=None):\n",
    "    if cl:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[f\"error_rate_{cl} mean\"],   row[\"significance_level\"]), axis=1)\n",
    "    else:\n",
    "        eval_df['square'] = eval_df.apply(lambda row: calculate_deviation_square(\n",
    "            row[\"error_rate mean\"], row[\"significance_level\"]), axis=1)\n",
    "    rmsd = np.round(math.sqrt(np.mean(eval_df[\"square\"])), 3)\n",
    "    return rmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets containing the chembio descriptors, labels and publication year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the size of the datasets containing the chembio descriptors, \n",
    "# they were uploaded to GitHub as tar.bz2 files and need to be unpacked first\n",
    "tar = tarfile.open(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is collected in the `files` dict, containing as keys the ChEMBL endpoint name and as value the dataframe\n",
    "files = {}\n",
    "for i, name in zip(tar, tar.getnames()):\n",
    "    file = tar.extractfile(i)\n",
    "    if file:  # Extraction also yields an empty folder (?) which will be ignored\n",
    "        n = name.split(\"/\")[1].split('_')[0]  # Get ChEMBL endpoint name from filename     \n",
    "        df = pd.read_csv(file)  # Read df\n",
    "        files[n] = df  # Store in dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataframe defining time-split thresholds per endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_thresh</th>\n",
       "      <th>update1_thresh</th>\n",
       "      <th>update2_thresh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chembl_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHEMBL220</th>\n",
       "      <td>2014</td>\n",
       "      <td>2016</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL4078</th>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL5763</th>\n",
       "      <td>2015</td>\n",
       "      <td>2016</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL203</th>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL206</th>\n",
       "      <td>2006</td>\n",
       "      <td>2012</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL279</th>\n",
       "      <td>2010</td>\n",
       "      <td>2013</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL230</th>\n",
       "      <td>2010</td>\n",
       "      <td>2013</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL340</th>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL240</th>\n",
       "      <td>2012</td>\n",
       "      <td>2014</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL2039</th>\n",
       "      <td>2014</td>\n",
       "      <td>2015</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL222</th>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHEMBL228</th>\n",
       "      <td>2009</td>\n",
       "      <td>2011</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_thresh  update1_thresh  update2_thresh\n",
       "chembl_id                                               \n",
       "CHEMBL220           2014            2016            2017\n",
       "CHEMBL4078          2014            2015            2016\n",
       "CHEMBL5763          2015            2016            2017\n",
       "CHEMBL203           2012            2014            2016\n",
       "CHEMBL206           2006            2012            2016\n",
       "CHEMBL279           2010            2013            2014\n",
       "CHEMBL230           2010            2013            2015\n",
       "CHEMBL340           2012            2014            2015\n",
       "CHEMBL240           2012            2014            2016\n",
       "CHEMBL2039          2014            2015            2017\n",
       "CHEMBL222           2009            2011            2015\n",
       "CHEMBL228           2009            2011            2014"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_df = pd.read_csv(time_split_threshold_path, index_col=0, \n",
    "                        usecols=[\"chembl_id\", \"train_thresh\", \"update1_thresh\", \"update2_thresh\"])\n",
    "splits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run experiment (train different acps, calibrate, and predict) for all endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEMBL279\n",
      "649 307 137 299\n",
      "CHEMBL220\n",
      "840 248 138 113\n",
      "CHEMBL4078\n",
      "1008 275 202 270\n",
      "CHEMBL5763\n",
      "600 75 95 114\n",
      "CHEMBL203\n",
      "433 213 291 167\n",
      "CHEMBL206\n",
      "325 63 97 105\n"
     ]
    }
   ],
   "source": [
    "evaluation_dfs = {\"cv_original\": [], 'original': [], \n",
    "                  'update1': [], 'update2': []}\n",
    "for endpoint in endpoints:\n",
    "    print(endpoint)\n",
    "    # Prepare data\n",
    "    X, y, years = load_data_per_endpoint(files, endpoint)\n",
    "    X_train, X_update1, X_update2, X_holdout,\\\n",
    "    y_train, y_update1, y_update2, y_holdout = split_data_per_endpoint(\n",
    "        X, y, years, splits_df\n",
    "    )\n",
    "    print(y_train.sum(), y_update1.sum(), y_update2.sum(), y_holdout.sum())\n",
    "    \n",
    "    # Define ACP and crossvalidator\n",
    "    acp = prepare_rf_acp()\n",
    "    cross_validator = CrossValidator(predictor=acp, cv_splitter=CrossValidationSampler())\n",
    "    # Crossvalidate using 'original' calibration set\n",
    "    cross_validator.cross_validate(\n",
    "        X_train=X_train, y_train=y_train, X_score=X_holdout, y_score=y_holdout,\n",
    "        steps=10, endpoint=endpoint\n",
    "    )\n",
    "    # Update calibration set within above crossvalidation loop\n",
    "    cross_validator.cross_validate_calibrate_update(\n",
    "        X_update=X_update1, y_update=y_update1, X_score=X_holdout, y_score=y_holdout, \n",
    "        steps=10, endpoint=endpoint\n",
    "    )\n",
    "    # Update calibration set again within above crossvalidation loop\n",
    "    cross_validator.cross_validate_calibrate_update(\n",
    "        X_update=X_update2, y_update=y_update2, X_score=X_holdout, y_score=y_holdout, \n",
    "        steps=10, endpoint=endpoint\n",
    "    )\n",
    "    # Store dataframes with evaluation values\n",
    "    # fixme: We could even save the calibration plots within this loop\n",
    "    \n",
    "    evaluation_dfs[\"original\"].append(cross_validator.averaged_evaluation_df_pred_score)\n",
    "    evaluation_dfs[\"cv_original\"].append(cross_validator.averaged_evaluation_df_cv)\n",
    "    evaluation_dfs[\"update1\"].append(cross_validator.averaged_evaluation_df_cal_update_1)\n",
    "    evaluation_dfs[\"update2\"].append(cross_validator.averaged_evaluation_df_cal_update_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rmsd's for all endpoints over all strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsds = {}\n",
    "for k, v in evaluation_dfs.items():\n",
    "    rmsds[k] = []\n",
    "    for df in v:\n",
    "        rmsd = calculate_rmsd_from_df(df)\n",
    "        rmsds[k].append(rmsd)\n",
    "rmsds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\"cv_original\", \"original\", \"update1\", \"update2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([rmsds[k] for k in strategies], labels=strategies)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"rmsd over all endpoints\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
